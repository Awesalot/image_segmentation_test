{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XSPK7j_MIYl"
      },
      "source": [
        "# Keras Tutorial\n",
        "\n",
        "Keras is a deep learning API written in Python, running on top of the machine learning platform TensorFlow. It was developed with a focus on enabling fast experimentation. \n",
        "\n",
        "The core data structures of Keras are layers and models. The simplest type of model is the Sequential model, a linear stack of layers. In this tutorial we will be creating a Convolutional Neural Network (CNN) using Keras to identify which number (from 0 to 9) is depicted by an image in the MNIST dataset.\n",
        "\n",
        "## CNN\n",
        "A **Convolutional Neural Network** (CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a CNN is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, CNNs have the ability to learn these filters/characteristics.\n",
        "\n",
        "Computers see images using pixels. Pixels in images are usually related. A convolution multiplies a matrix of pixels with a filter matrix or ‘kernel’ and sums up the multiplication values. Then the convolution slides over to the next pixel and repeats the same process until all the image pixels have been covered. The objective of the convolution operation is to extract the high-level features such as edges, from the input image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z22Os3z-7OS"
      },
      "source": [
        "# Done so that the output of plotting commands is displayed inline, directly below the code cell that produced it.\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqzbDEP__EVR"
      },
      "source": [
        "# Importing all the required modules\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrHaM15FNQM9"
      },
      "source": [
        "## Data Setup\n",
        "\n",
        "### Importing the data\n",
        "\n",
        "The MNIST dataset is conveniently provided to us as part of the Keras library, so we can easily load the dataset. Out of the 70,000 images provided in the dataset, 60,000 are given for training and 10,000 are given for testing.\n",
        "\n",
        "When we load the dataset below, X_train and X_test will contain the images, and y_train and y_test will contain the digits that those images represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I6yJNxY_ISt",
        "outputId": "3a75289b-f36b-4eac-ef30-2a46d0f3f784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kUB8iA6TW9W"
      },
      "source": [
        "We will plot the first image in our dataset and check its size using the ‘shape’ function. This gives us an idea of what the data looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxLMEdeG_NWK",
        "outputId": "0e7f9f3a-15c1-42ab-9ad7-75414212f82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#plot the first image in the dataset\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f10b522ca20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMKhJJ64_P0V",
        "outputId": "7502a21b-77a7-4c52-a72a-fc9f8b68c187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#check image shape\n",
        "X_train[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FTLuZJsTg-3"
      },
      "source": [
        "By default, the shape of every image in the mnist dataset is 28 x 28, so we will not need to check the shape of all the images.\n",
        "\n",
        "### Data Pre-processing\n",
        "\n",
        "Next, we need to reshape our dataset inputs (X_train and X_test) to the shape that our model expects when we train the model. The first number is the number of images (60,000 for X_train and 10,000 for X_test). Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bezZovq_WdA"
      },
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xybjxr3zUJvU"
      },
      "source": [
        "We need to ‘one-hot-encode’ our target variable. This means that a column will be created for each output category and a binary variable is inputted for each category. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POykGt50_ZA1",
        "outputId": "926c84b1-14a8-4fef-b44e-369492c69439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "y_train[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agdzOTbaUMXQ"
      },
      "source": [
        "The above output tells us that the number depicted is 5 as the sixth  index of the array is 1 and the rest are 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSt2T0LsUy9N"
      },
      "source": [
        "## CNN with Keras\n",
        "\n",
        "Keras has multiple options to create models. The model type that we will be using is Sequential. It allows you to build a model layer by layer. We use the `add()` function to add layers to our model.\n",
        "\n",
        "The layers in our model as designed above are as follows -\n",
        "1. **Conv2D layers**: Our first 2 layers are Conv2D layers. These are convolution layers that will deal with our input images, which are seen as 2-dimensional matrices. 64 in the first layer and 32 in the second layer are the number of nodes in each layer. This number can be adjusted to be higher or lower, depending on the size of the dataset.\n",
        "2. **Flatten layer**: It serves as a connection between the convolution and dense layers.\n",
        "3. **Dense layer**: It is the layer type we use for our output layer. Dense is a standard layer type that is used in many cases for neural networks. We will have 10 nodes in our output layer, one for each possible outcome (0–9).\n",
        "\n",
        "The following is the code for building the model using Keras -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNffsCoE_bUs"
      },
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQwFgDwENUCT"
      },
      "source": [
        "\n",
        "\n",
        "* **Kernel size**: It is the size of the filter matrix for our convolution. So a kernel size of 3 means we will have a 3x3 filter matrix.\n",
        "* **Activation**: It is the activation function for the layer.\n",
        "    * **ReLU**: The rectified linear activation function (ReLU) for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero. `relu` is the activation function for the first two layers.\n",
        "    * **Softmax**: The activation for the Dense layer is `softmax`. It makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has the highest probability.\n",
        "\n",
        "* **Shape**: It is the shape of each input image i.e. 28,28,1 as seen earlier on, with the 1 signifying that the images are greyscale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri9TjylFatB5"
      },
      "source": [
        "### Compiling the model\n",
        "\n",
        "Next, we need to compile our model. Compiling the model takes three parameters: **optimizer**, **loss** and **metrics**.\n",
        "* The optimizer controls the learning rate. We will be using `adam` as our optmizer. Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n",
        "* The learning rate determines how fast the optimal weights for the model are calculated. A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
        "* We will use `categorical_crossentropy` for our loss function. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
        "* To make things even easier to interpret, we will use the `accuracy` metric to see the accuracy score on the validation set when we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAOg2WXS5mW3",
        "outputId": "b498e627-372b-4537-970d-ee6321f5cca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#compile model using accuracy as a measure of model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        18464     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                184330    \n",
            "=================================================================\n",
            "Total params: 203,434\n",
            "Trainable params: 203,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P1kQLvubOK6"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "Now we will train our model. To train, we will use the `fit()` function on our model with the following parameters: training data (train_X), target data (train_y), validation data, and the number of epochs. For our validation data, we will use the test set provided to us in our dataset, which we have split into X_test and y_test.\n",
        "\n",
        "The number of epochs is the number of times the model will cycle through the data. For our model, we will set the number of epochs to 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bRzhcrU_eWU",
        "outputId": "5ad64baf-d976-4f99-f58d-f79593476f12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#train model\n",
        "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 175s 93ms/step - loss: 0.2021 - accuracy: 0.9526 - val_loss: 0.0822 - val_accuracy: 0.9756\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 172s 92ms/step - loss: 0.0632 - accuracy: 0.9803 - val_loss: 0.0666 - val_accuracy: 0.9783\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 170s 91ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.0783 - val_accuracy: 0.9770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f10ae572eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-iOh9v0NkVY"
      },
      "source": [
        "## Testing\n",
        "\n",
        "If you want to see the actual predictions that our model has made for the test data, we can use the predict function. The predict function will give an array with 10 numbers. These numbers are the probabilities that the input image represents each digit (0–9). The array index with the highest number represents the model prediction. The sum of each array equals 1 (since each number is a probability).\n",
        "\n",
        "To show this, we will show the predictions for the first 4 images in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lURvUIRi6c64",
        "outputId": "440d506c-25d8-4d1b-811e-2cefe3a98daf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#show predictions for the first 3 images in the test set\n",
        "np.around(model.predict(X_test[:4]), decimals = 4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.000e+00, 0.000e+00, 2.000e-04, 1.000e-04, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 9.997e-01, 0.000e+00, 0.000e+00],\n",
              "       [0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
              "       [1.000e-04, 9.186e-01, 1.000e-04, 0.000e+00, 4.700e-03, 3.000e-04,\n",
              "        5.000e-04, 0.000e+00, 7.570e-02, 0.000e+00],\n",
              "       [9.997e-01, 0.000e+00, 3.000e-04, 0.000e+00, 0.000e+00, 0.000e+00,\n",
              "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVxiyIDwutot"
      },
      "source": [
        "Let’s compare this with the actual values -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VZT14Z76k5k",
        "outputId": "c3bad39f-ca25-4a01-b472-d64775b0f27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#show actual results for the first 3 images in the test set\n",
        "y_test[:4]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3T4-AKruv67"
      },
      "source": [
        "We can convert the above arrays into a more readable format using the code below -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qasGpp7c8_mE",
        "outputId": "f6797366-eed0-4179-af33-4b1a8d49e46f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "j = 4\n",
        "for i in y_test[:j]:\n",
        "  result = np.where(i == 1)\n",
        "  print(\"The image at index number {} has the number\".format(4 - j), result[0], sep = ' ')\n",
        "  j = j-1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image at index number 0 has the number [7]\n",
            "The image at index number 1 has the number [2]\n",
            "The image at index number 2 has the number [1]\n",
            "The image at index number 3 has the number [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLsUuTURu70A"
      },
      "source": [
        "The actual values show that the first four images are 7, 2, 1 and 0. This matches up with our model's predictions. Thus we are able to realize a CNN using Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqMBuYGMMwUy"
      },
      "source": [
        "# References\n",
        "\n",
        "1. [Blog Post: Building a Convolutional Neural Network (CNN) in Keras by Eijaz Allibhai](https://towardsdatascience.com/building-a-convolutional-neural-network-cnn-in-keras-329fbbadc5f5)\n",
        "2. [Keras Offical Documentation](https://keras.io/about/)"
      ]
    }
  ]
}